{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use whole base model until head, and change the head with a custom head\n",
    "2. fine tune when you have a large and similar dataset\n",
    "3. train hole model if you have large and different dataset\n",
    "4. small and dif --> fine tuning\n",
    "5. small and similar --> transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O ./resources/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './resources/cats_and_dogs_filtered.zip'\n",
    "zip_object = zipfile.ZipFile(file=dataset_path, mode=\"r\")\n",
    "zip_object.extractall(\"./resources\")\n",
    "zip_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_new = \"./resources/cats_and_dogs_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_path_new, \"train\")\n",
    "validation_dir = os.path.join(dataset_path_new, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_model = tf.keras.applications.MobileNetV2(input_shape=IMAGE_SIZE, include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change trainable to false to build on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()(mobile_net_model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction layer same size as classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(global_avg_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=mobile_net_model.input, outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-trained architectures only support certain input sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    for example: MobileNet only supports:(96,96), (128,128), (160,160), (192,192), (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_train = ImageDataGenerator(rescale=1/255.0)\n",
    "data_gen_valid = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_gen_train.flow_from_directory(train_dir, target_size=(128,128), batch_size=128, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator = data_gen_valid.flow_from_directory(validation_dir, target_size=(128,128), batch_size=128, class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - ETA: 48s - loss: 0.8734 - accuracy: 0.429 - ETA: 24s - loss: 0.8691 - accuracy: 0.414 - ETA: 16s - loss: 0.8464 - accuracy: 0.447 - ETA: 12s - loss: 0.8480 - accuracy: 0.439 - ETA: 9s - loss: 0.8498 - accuracy: 0.432 - ETA: 8s - loss: 0.8517 - accuracy: 0.43 - ETA: 7s - loss: 0.8429 - accuracy: 0.44 - ETA: 6s - loss: 0.8490 - accuracy: 0.44 - ETA: 5s - loss: 0.8370 - accuracy: 0.45 - ETA: 4s - loss: 0.8322 - accuracy: 0.45 - ETA: 4s - loss: 0.8272 - accuracy: 0.46 - ETA: 3s - loss: 0.8290 - accuracy: 0.46 - ETA: 2s - loss: 0.8276 - accuracy: 0.46 - ETA: 1s - loss: 0.8217 - accuracy: 0.47 - ETA: 0s - loss: 0.8194 - accuracy: 0.47 - 18s 1s/step - loss: 0.8185 - accuracy: 0.4750 - val_loss: 0.7693 - val_accuracy: 0.5030\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - ETA: 5s - loss: 0.7547 - accuracy: 0.55 - ETA: 4s - loss: 0.7788 - accuracy: 0.50 - ETA: 4s - loss: 0.7788 - accuracy: 0.51 - ETA: 3s - loss: 0.7836 - accuracy: 0.52 - ETA: 3s - loss: 0.7648 - accuracy: 0.53 - ETA: 3s - loss: 0.7644 - accuracy: 0.53 - ETA: 2s - loss: 0.7558 - accuracy: 0.54 - ETA: 2s - loss: 0.7527 - accuracy: 0.54 - ETA: 2s - loss: 0.7497 - accuracy: 0.54 - ETA: 1s - loss: 0.7505 - accuracy: 0.54 - ETA: 1s - loss: 0.7448 - accuracy: 0.54 - ETA: 1s - loss: 0.7412 - accuracy: 0.54 - ETA: 0s - loss: 0.7357 - accuracy: 0.55 - ETA: 0s - loss: 0.7349 - accuracy: 0.55 - ETA: 0s - loss: 0.7309 - accuracy: 0.55 - 7s 465ms/step - loss: 0.7317 - accuracy: 0.5540 - val_loss: 0.6851 - val_accuracy: 0.5860\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - ETA: 4s - loss: 0.7331 - accuracy: 0.50 - ETA: 4s - loss: 0.7365 - accuracy: 0.53 - ETA: 4s - loss: 0.7141 - accuracy: 0.55 - ETA: 3s - loss: 0.7151 - accuracy: 0.56 - ETA: 3s - loss: 0.7142 - accuracy: 0.57 - ETA: 3s - loss: 0.7105 - accuracy: 0.57 - ETA: 2s - loss: 0.7084 - accuracy: 0.57 - ETA: 2s - loss: 0.6940 - accuracy: 0.58 - ETA: 2s - loss: 0.6894 - accuracy: 0.59 - ETA: 1s - loss: 0.6880 - accuracy: 0.59 - ETA: 1s - loss: 0.6824 - accuracy: 0.60 - ETA: 1s - loss: 0.6765 - accuracy: 0.60 - ETA: 0s - loss: 0.6778 - accuracy: 0.60 - ETA: 0s - loss: 0.6754 - accuracy: 0.60 - ETA: 0s - loss: 0.6726 - accuracy: 0.60 - 7s 466ms/step - loss: 0.6737 - accuracy: 0.6050 - val_loss: 0.6151 - val_accuracy: 0.6600\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - ETA: 4s - loss: 0.7465 - accuracy: 0.54 - ETA: 4s - loss: 0.7089 - accuracy: 0.58 - ETA: 3s - loss: 0.6805 - accuracy: 0.59 - ETA: 3s - loss: 0.6756 - accuracy: 0.60 - ETA: 3s - loss: 0.6649 - accuracy: 0.62 - ETA: 3s - loss: 0.6653 - accuracy: 0.61 - ETA: 2s - loss: 0.6574 - accuracy: 0.62 - ETA: 2s - loss: 0.6528 - accuracy: 0.63 - ETA: 2s - loss: 0.6488 - accuracy: 0.63 - ETA: 1s - loss: 0.6368 - accuracy: 0.65 - ETA: 1s - loss: 0.6347 - accuracy: 0.65 - ETA: 1s - loss: 0.6348 - accuracy: 0.64 - ETA: 0s - loss: 0.6306 - accuracy: 0.65 - ETA: 0s - loss: 0.6276 - accuracy: 0.65 - ETA: 0s - loss: 0.6242 - accuracy: 0.65 - 7s 463ms/step - loss: 0.6221 - accuracy: 0.6575 - val_loss: 0.5539 - val_accuracy: 0.7210\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - ETA: 5s - loss: 0.6409 - accuracy: 0.64 - ETA: 4s - loss: 0.6160 - accuracy: 0.64 - ETA: 4s - loss: 0.5849 - accuracy: 0.67 - ETA: 3s - loss: 0.5911 - accuracy: 0.66 - ETA: 3s - loss: 0.5938 - accuracy: 0.67 - ETA: 3s - loss: 0.5895 - accuracy: 0.67 - ETA: 2s - loss: 0.5903 - accuracy: 0.67 - ETA: 2s - loss: 0.5872 - accuracy: 0.68 - ETA: 2s - loss: 0.5819 - accuracy: 0.68 - ETA: 1s - loss: 0.5853 - accuracy: 0.68 - ETA: 1s - loss: 0.5786 - accuracy: 0.69 - ETA: 1s - loss: 0.5719 - accuracy: 0.70 - ETA: 0s - loss: 0.5720 - accuracy: 0.70 - ETA: 0s - loss: 0.5711 - accuracy: 0.70 - ETA: 0s - loss: 0.5715 - accuracy: 0.70 - 7s 464ms/step - loss: 0.5710 - accuracy: 0.7010 - val_loss: 0.5005 - val_accuracy: 0.7790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f2d8ee04a8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=5, validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate_generator(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do not use fine tuning on the whole network; only a few top layers are enough. In most cases, they are specialized. The goal of the fine tuning is to adopt that specific part of the network for our custom (new) dataset.\n",
    "- Start  with fine tuning after you have finished with transfer learning step. If we try to perform fine tuning immediately, gradients will be much different between our custom head layer and a few unfrozen layers from the base model.\n",
    "- On a small dataset fine tuning will cause your model to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mobile_net_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mobile_net_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - ETA: 10s - loss: 0.5120 - accuracy: 0.757 - ETA: 7s - loss: 0.3951 - accuracy: 0.839 - ETA: 6s - loss: 0.3442 - accuracy: 0.86 - ETA: 5s - loss: 0.3034 - accuracy: 0.88 - ETA: 4s - loss: 0.2716 - accuracy: 0.90 - ETA: 4s - loss: 0.2566 - accuracy: 0.90 - ETA: 3s - loss: 0.2418 - accuracy: 0.91 - ETA: 3s - loss: 0.2330 - accuracy: 0.91 - ETA: 2s - loss: 0.2236 - accuracy: 0.92 - ETA: 2s - loss: 0.2164 - accuracy: 0.92 - ETA: 1s - loss: 0.2118 - accuracy: 0.92 - ETA: 1s - loss: 0.2023 - accuracy: 0.92 - ETA: 1s - loss: 0.1927 - accuracy: 0.93 - ETA: 0s - loss: 0.1882 - accuracy: 0.93 - ETA: 0s - loss: 0.1816 - accuracy: 0.93 - 8s 513ms/step - loss: 0.1748 - accuracy: 0.9375 - val_loss: 0.1090 - val_accuracy: 0.9610\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - ETA: 5s - loss: 0.0244 - accuracy: 1.00 - ETA: 5s - loss: 0.0304 - accuracy: 0.99 - ETA: 4s - loss: 0.0330 - accuracy: 0.99 - ETA: 4s - loss: 0.0301 - accuracy: 0.99 - ETA: 4s - loss: 0.0335 - accuracy: 0.99 - ETA: 3s - loss: 0.0330 - accuracy: 0.99 - ETA: 3s - loss: 0.0346 - accuracy: 0.99 - ETA: 2s - loss: 0.0351 - accuracy: 0.99 - ETA: 2s - loss: 0.0339 - accuracy: 0.99 - ETA: 2s - loss: 0.0328 - accuracy: 0.99 - ETA: 1s - loss: 0.0324 - accuracy: 0.99 - ETA: 1s - loss: 0.0321 - accuracy: 0.99 - ETA: 1s - loss: 0.0312 - accuracy: 0.99 - ETA: 0s - loss: 0.0306 - accuracy: 0.99 - ETA: 0s - loss: 0.0297 - accuracy: 0.99 - 8s 501ms/step - loss: 0.0295 - accuracy: 0.9950 - val_loss: 0.1131 - val_accuracy: 0.9610\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - ETA: 5s - loss: 0.0089 - accuracy: 1.00 - ETA: 5s - loss: 0.0100 - accuracy: 1.00 - ETA: 4s - loss: 0.0106 - accuracy: 1.00 - ETA: 4s - loss: 0.0104 - accuracy: 1.00 - ETA: 3s - loss: 0.0110 - accuracy: 1.00 - ETA: 3s - loss: 0.0104 - accuracy: 1.00 - ETA: 3s - loss: 0.0098 - accuracy: 1.00 - ETA: 2s - loss: 0.0097 - accuracy: 1.00 - ETA: 2s - loss: 0.0111 - accuracy: 0.99 - ETA: 2s - loss: 0.0106 - accuracy: 0.99 - ETA: 1s - loss: 0.0102 - accuracy: 0.99 - ETA: 1s - loss: 0.0100 - accuracy: 0.99 - ETA: 1s - loss: 0.0098 - accuracy: 0.99 - ETA: 0s - loss: 0.0096 - accuracy: 0.99 - ETA: 0s - loss: 0.0095 - accuracy: 0.99 - 8s 492ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.1552 - val_accuracy: 0.9560\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - ETA: 5s - loss: 0.0054 - accuracy: 1.00 - ETA: 4s - loss: 0.0046 - accuracy: 1.00 - ETA: 4s - loss: 0.0046 - accuracy: 1.00 - ETA: 4s - loss: 0.0054 - accuracy: 1.00 - ETA: 3s - loss: 0.0056 - accuracy: 1.00 - ETA: 3s - loss: 0.0055 - accuracy: 1.00 - ETA: 3s - loss: 0.0059 - accuracy: 1.00 - ETA: 2s - loss: 0.0056 - accuracy: 1.00 - ETA: 2s - loss: 0.0052 - accuracy: 1.00 - ETA: 2s - loss: 0.0049 - accuracy: 1.00 - ETA: 1s - loss: 0.0051 - accuracy: 1.00 - ETA: 1s - loss: 0.0049 - accuracy: 1.00 - ETA: 1s - loss: 0.0048 - accuracy: 1.00 - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 8s 497ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9610\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - ETA: 5s - loss: 0.0037 - accuracy: 1.00 - ETA: 4s - loss: 0.0026 - accuracy: 1.00 - ETA: 4s - loss: 0.0027 - accuracy: 1.00 - ETA: 3s - loss: 0.0027 - accuracy: 1.00 - ETA: 3s - loss: 0.0024 - accuracy: 1.00 - ETA: 3s - loss: 0.0021 - accuracy: 1.00 - ETA: 3s - loss: 0.0021 - accuracy: 1.00 - ETA: 2s - loss: 0.0020 - accuracy: 1.00 - ETA: 2s - loss: 0.0019 - accuracy: 1.00 - ETA: 2s - loss: 0.0019 - accuracy: 1.00 - ETA: 1s - loss: 0.0021 - accuracy: 1.00 - ETA: 1s - loss: 0.0020 - accuracy: 1.00 - ETA: 1s - loss: 0.0020 - accuracy: 1.00 - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 8s 498ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f2d7690080>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=5, validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_accuracy = model.evaluate_generator(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959\n"
     ]
    }
   ],
   "source": [
    "print(valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
